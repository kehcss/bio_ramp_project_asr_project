{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f385e7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 3729 entries. Output saved to eval_after_new.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def add_length_attribute(input_filepath, output_filepath):\n",
    "    # Load original JSON data\n",
    "    with open(input_filepath, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    texts = data.get(\"all_generated_texts\", [])\n",
    "\n",
    "    # Build new structure with text and length attributes\n",
    "    new_texts = [{\"text\": t, \"length\": len(t)} for t in texts]\n",
    "    \n",
    "    # include \"id\" attribute\n",
    "    for i, text in enumerate(new_texts):\n",
    "        text[\"id\"] = i\n",
    "    \n",
    "    \n",
    "\n",
    "    # Create final dict\n",
    "    output_data = {\"texts\": new_texts}\n",
    "\n",
    "    # Write output JSON file\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as f_out:\n",
    "        json.dump(output_data, f_out, ensure_ascii=False, indent=2)\n",
    "        \n",
    "    # save as a csv file\n",
    "    with open(output_filepath.replace('.json', '.csv'), 'w', encoding='utf-8') as f_out:\n",
    "        f_out.write(\"id,text,length\\n\")\n",
    "        for text in new_texts:\n",
    "            f_out.write(f\"{text['id']},{text['text']},{text['length']}\\n\")\n",
    "# Print the number of entries processed\n",
    "\n",
    "    print(f\"Processed {len(texts)} entries. Output saved to {output_filepath}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"eval_before.json\"   # Change if your file is named differently or in another folder\n",
    "    output_file = \"eval_after_new.json\"       # Output filename\n",
    "\n",
    "    add_length_attribute(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a854b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_653783/2481388163.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df[\"id\"] = filtered_df.index\n"
     ]
    }
   ],
   "source": [
    "## Read the test.csv file\n",
    "import pandas as pd\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "# filter the dataframe to include only language = \"igbo\", \"yoruba\", \"hausa\"\n",
    "filtered_df = test_df[test_df[\"language\"].isin([\"igbo\", \"yoruba\", \"hausa\"])]\n",
    "\n",
    "# add \"id\" attribute which is the index of the dataframe and reset to start from 0\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "filtered_df[\"id\"] = filtered_df.index\n",
    "\n",
    "\n",
    "#save the filtered dataframe to a csv file\n",
    "filtered_df.to_csv(\"test_filtered.csv\", index=False, encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6940d507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame columns: Index(['speaker_id', 'transcription', 'audio_path', 'duration', 'language',\n",
      "       'gender', 'translation', 'domain', 'id'],\n",
      "      dtype='object')\n",
      "Eval DataFrame columns: Index(['text', 'length', 'id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Imoort the json files\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "filtered_df = pd.read_json(\"test_filtered.json\", lines=True)\n",
    "eval_df = pd.read_json(\"eval_after_new.json\")\n",
    "\n",
    "print(\"Filtered DataFrame columns:\", filtered_df.columns)\n",
    "print(\"Eval DataFrame columns:\", eval_df.columns)\n",
    "\n",
    "# merge the two dataframes on the \"id\" column\n",
    "merged_df = pd.merge(filtered_df[[\"language\", \"audio_path\", \"id\", \"transcription\"]], eval_df, on=\"id\", how=\"inner\")\n",
    "\n",
    "# columns renaming\n",
    "merged_df.rename(columns={\"text\": \"ph-4_generated_text\", \"transcription\": \"ground_truth\"}, inplace=True)\n",
    "\n",
    "\n",
    "#save the merged dataframe to a json file\n",
    "merged_df.to_json(\"merged_eval_before.json\", orient=\"records\", lines=True, force_ascii=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bio_ramp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
